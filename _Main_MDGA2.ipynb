{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_Main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/CrispyMice/blob/main/_Main_MDGA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'Get Standard Modules'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import os\n",
        "from scipy.signal import butter,filtfilt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import warnings\n",
        "import shutil\n",
        "from google.colab import files\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "clear_output(wait=False)"
      ],
      "metadata": {
        "id": "JB3cLtpu5iXZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try: shutil.rmtree('/content/EphysLib')\n",
        "except: None\n",
        "\n",
        "\"run dtabuena's ephys notebooks\"\n",
        "!git clone https://github.com/dtabuena/EphysLib\n",
        "\n",
        "to_import = [\n",
        "          'ABF_Quality_Control.ipynb',\n",
        "          'Basic_Ephys.ipynb',\n",
        "          'Firing_Rate_Gain.ipynb',\n",
        "          'Simple_ABF_tools.ipynb',\n",
        "          'IV_analyzer.ipynb',\n",
        "          'Vm_analyzer.ipynb',\n",
        "          'membrane_analyzer.ipynb',\n",
        "          'analyze_rheobase.ipynb',\n",
        "          'fun_math.ipynb',\n",
        "          'importing_abfs_from_dropbox.ipynb',\n",
        "          'input_resistance_analyzer.ipynb',\n",
        "          'latencey_analyzer.ipynb',\n",
        "          'QC_recoding_dataframe.ipynb'\n",
        "            ]\n",
        "\n",
        "for i in to_import:\n",
        "    f = '/content/EphysLib/' + i\n",
        "    %run $f\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4lZ-pjFGrf_",
        "outputId": "4300fad3-b6c5-4f4b-f3d0-513e91880a91"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EphysLib'...\n",
            "remote: Enumerating objects: 241, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 241 (delta 98), reused 29 (delta 29), pack-reused 94\u001b[K\n",
            "Receiving objects: 100% (241/241), 203.35 KiB | 5.50 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyabf in /usr/local/lib/python3.7/dist-packages (2.3.6)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pyabf) (1.21.6)\n",
            "Requirement already satisfied: pytest>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from pyabf) (3.6.4)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pyabf) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pyabf) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pyabf) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pyabf) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pyabf) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pyabf) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (57.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (22.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (1.15.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (1.11.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (8.14.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.0.7->pyabf) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'Import and catalog source data'\n",
        "'RNF182 Dropbox'\n",
        "data_source = \"https://www.dropbox.com/sh/n9t8p257wnzlijk/AAC9Z36JodisyZjnM3mkJC3Xa?dl=0\"\n",
        "file_loc = get_drobox_folder(data_source, 'my_ephys_data.zip')\n",
        "clear_output(wait=False)\n",
        "file_naming_scheme = ['Rec_date','Virus','GenoType','Sex','Age','Slice_Num','Cell_num','Cell_Type']\n",
        "# abf_recordings_df,protocol_set = catalogue_recs(file_loc,file_naming_scheme)\n",
        "cell_prot_lut(abf_recordings_df,protocol_set,csv_name='RNF182_LUT')\n",
        "print('Protocol_Names:')\n",
        "_ = [print(p) for p in protocol_set]"
      ],
      "metadata": {
        "id": "MYTtLS5v5V-J",
        "outputId": "d833afdc-7f20-4d4d-bf22-8b3323f49555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23f8112c-ebb7-425e-a899-3c32472ce6c9\", \"RNF182_LUT.csv\", 13422)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protocol_Names:\n",
            "IC - Sag - D50pA\n",
            "VC - MemTest-10ms-160ms\n",
            "VC - Multi IV - 150ms\n",
            "IC - R input\n",
            "IC - Rheobase\n",
            "IC - Latentcy 800pA-1s\n",
            "VC - 3min GapFree\n",
            "IC - Gain - D50pA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VC_prot = ['VC - MemTest-10ms-160ms',\n",
        "           'VC - Multi IV - 150ms',]\n",
        "IC_prot = ['IC - Gain - D20pA',\n",
        "           'IC - Gain - D50pA',\n",
        "           'IC - Rheobase',\n",
        "           'IC - R input',\n",
        "           'IC - Latentcy 800pA-1s'\n",
        "           'VC - 3min GapFree']\n",
        "\n",
        "abf_recordings_df, _ = purge_wrong_clamp(abf_recordings_df,VC_prot,IC_prot)"
      ],
      "metadata": {
        "id": "7A4t8U0ea33E"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analysis_iterator(abf_recordings_df,func_dict,arg_dict):\n",
        "    problem_recs = []\n",
        "    def init_col_object(df,name): \n",
        "        df[name] = None\n",
        "        df[name] = df[name].astype(object)\n",
        "        return df\n",
        "\n",
        "    for file_name in tqdm(abf_recordings_df.index):\n",
        "        abf = abf_or_name(file_name)\n",
        "        prot_name = abf.protocol\n",
        "\n",
        "\n",
        "        # check for keyed protocol\n",
        "        if prot_name not in func_dict.keys():\n",
        "            # print('unknown protocol(func): ',  prot_name)\n",
        "            continue\n",
        "        if prot_name not in arg_dict.keys():\n",
        "            # print('unknown protocol(args): ',  prot_name)\n",
        "            continue\n",
        "\n",
        "\n",
        "        try:\n",
        "            analyzer_func = func_dict[prot_name]  # get analyzer from dict\n",
        "            args_for_analyzer =  [abf] + arg_dict[prot_name] # get args for analyzer from dict\n",
        "            results = analyzer_func(*args_for_analyzer) # run analyzer\n",
        "            for k in results.keys():\n",
        "\n",
        "                # New Col?\n",
        "                cols = abf_recordings_df.columns\n",
        "                if k not in cols:\n",
        "                    abf_recordings_df = init_col_object(abf_recordings_df,k)\n",
        "                abf_recordings_df.at[file_name,k] = results[k]\n",
        "        except: \n",
        "            print('error on: ' ,file_name)\n",
        "            problem_recs.append(file_name)\n",
        "\n",
        "    return abf_recordings_df, problem_recs\n",
        "\n",
        "\n",
        "spike_args =  {'spike_thresh':20, 'high_dv_thresh': 25,'low_dv_thresh': -5,'window_ms': 2}\n",
        "\n",
        "func_dict = {}\n",
        "arg_dict = {}\n",
        "\n",
        "func_dict['VC - 3min GapFree']= rmp_analyzer\n",
        "arg_dict['VC - 3min GapFree'] = [False]\n",
        "\n",
        "\n",
        "func_dict['IC - Rheobase']= rheobase_analyzer\n",
        "arg_dict['IC - Rheobase'] = [spike_args, False, False, False]  # [spike_args, to_plot, verbose, force_singlespike]\n",
        "\n",
        "func_dict['IC - Gain - D20pA']= gain_analyzer\n",
        "arg_dict['IC - Gain - D20pA']= [spike_args, 0.8, 0]  # [spike_args, to_plot, verbose, force_singlespike]\n",
        "func_dict['IC - Gain - D50pA']= func_dict['IC - Gain - D20pA'] \n",
        "arg_dict['IC - Gain - D50pA']= arg_dict['IC - Gain - D20pA']\n",
        "\n",
        "func_dict['VC - MemTest-10ms-160ms']= membrane_analyzer\n",
        "arg_dict['VC - MemTest-10ms-160ms']= [False, False, ['Ra', 'Rm', 'Cm', 'tau',\t'Cmq',\t'Cmf',\t'Cmqf', 'Cm_pc']]  # [to_plot, verbose]\n",
        "\n",
        "func_dict['IC - Latentcy 800pA-1s']= latencey_analyzer \n",
        "arg_dict['IC - Latentcy 800pA-1s']= [spike_args, False]  # [spike_args, to_plot]\n",
        "\n",
        "func_dict['IC - Latentcy 800pA-1s']= latencey_analyzer \n",
        "arg_dict['IC - Latentcy 800pA-1s']= [spike_args, False]  # [spike_args, to_plot]\n",
        "\n",
        "func_dict['IC - R input']= input_resistance_analyzer \n",
        "arg_dict['IC - R input']= [[-30, 10] ,False]  # [dVm_limits, to_plot]\n",
        "\n",
        "\n",
        "func_dict['VC - Multi IV - 150ms'] = IV_analyzer\n",
        "arg_dict['VC - Multi IV - 150ms']= [{'IV_Early':(16.5, 30),'IV_Steady_State':(100,120)} ,False]  # [measure_windows, to_plot]\n",
        "\n",
        "\n",
        "abf_recordings_df, problem_recs = analysis_iterator(abf_recordings_df,func_dict,arg_dict)\n",
        "print(problem_recs)\n",
        "\n",
        "# abf_recordings_df.to_csv('test.csv')\n",
        "# files.download('test.csv')"
      ],
      "metadata": {
        "id": "CANQTWscKMtA",
        "outputId": "4c518e49-382e-454f-d220-7d8c60e2ddc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 9/251 [00:16<10:45,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ap_stats_failed:  ABF (v2.9) with 2 channels (mV, pA), sampled at 10.0 kHz, containing 3 sweeps, having no tags, with a total length of 0.57 minutes, recorded with protocol \"IC - Rheobase\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 59/251 [00:58<01:57,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error on:  my_ephys_data/2022_08_12_RNF182/2022x08x12_RNF182_E4KI_F_P251_s002_c006_CA3xPOS_0006.abf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 164/251 [02:43<02:21,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ap_stats_failed:  ABF (v2.9) with 2 channels (mV, pA), sampled at 10.0 kHz, containing 7 sweeps, having no tags, with a total length of 1.23 minutes, recorded with protocol \"IC - Rheobase\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 251/251 [04:11<00:00,  1.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my_ephys_data/2022_08_12_RNF182/2022x08x12_RNF182_E4KI_F_P251_s002_c006_CA3xPOS_0006.abf']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abf_recordings_df.to_csv('test.csv')\n",
        "files.download('test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "j014oTi-_3SV",
        "outputId": "2674e1ad-05b5-43c0-fe4a-d424a93eae8f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_660800e3-1a64-4a53-9cb9-c515a6cf80f1\", \"test.csv\", 131783)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cell_sorting(abf_recordings_df):\n",
        "\n",
        "    unique_cells = list(set(abf_recordings_df['cell_id']))\n",
        "    unique_cells.sort()\n",
        "    transfer_cols = [c for c in abf_recordings_df.columns if 'cell_id' not in c]\n",
        "    cell_df = pd.DataFrame(index=list(unique_cells),columns = transfer_cols)\n",
        "    \n",
        "\n",
        "    for cell in cell_df.index:\n",
        "        match = [cell in r for r in abf_recordings_df['cell_id']]\n",
        "        for col in transfer_cols:\n",
        "            match_values = list(abf_recordings_df[match][col])\n",
        "            # print('col', col)\n",
        "            # print(match_values)\n",
        "\n",
        "            cell_df.at[cell,col] = match_values\n",
        "    return cell_df\n",
        "\n",
        "def consolidate_iv_recs(multi_vals):\n",
        "    multi_vals = [v for v in multi_vals if v is not None]   \n",
        "    v_stim = [  mv['V_stim'] for mv in  multi_vals ]\n",
        "    peak_vals = [  mv['I_peak'] for mv in  multi_vals ]\n",
        "    if len(v_stim)>1:\n",
        "        rec_lengths = [len(v) for v in v_stim]\n",
        "        long_enough = np.where(np.array(rec_lengths) > 5)[0][0]\n",
        "        multi_vals = multi_vals[long_enough]\n",
        "        # print(multi_vals)  \n",
        "    return multi_vals\n",
        "\n",
        "\n",
        "\n",
        "def cell_consolidation(cell_df,list_types,any_types,average_types = True):\n",
        "    cell_df_con = cell_df.copy()\n",
        "    explicit_cols = ['IV_Early','IV_Steady_State','Stim_Levels_(pA)','Spike_Counts']\n",
        "\n",
        "    if average_types:\n",
        "        average_types = [c for c in cell_df_con.columns if c not in any_types and c not in list_types and c not in explicit_cols]\n",
        "        \n",
        "        # print('average_types',average_types)\n",
        "\n",
        "\n",
        "\n",
        "    for cell in cell_df_con.index:\n",
        "        for col in list_types:\n",
        "            'do nothing, keep the list'\n",
        "        for col in any_types:\n",
        "            'they are all the same take the first'\n",
        "            cell_df_con.at[cell,col] = cell_df_con.at[cell,col][0]\n",
        "\n",
        "        for col in average_types:\n",
        "            multi_vals = cell_df_con.loc[cell,col]\n",
        "            try:\n",
        "                multi_vals = [v for v in multi_vals if v is not None]\n",
        "                single_val = np.nanmean(multi_vals,0)\n",
        "                cell_df_con.at[cell,col] = single_val\n",
        "                # print(single_val)\n",
        "            except: 'Just keep going None'\n",
        "        \n",
        "\n",
        "    # explicitly defined consolidations\n",
        "    for col in ['IV_Early', 'IV_Steady_State']:\n",
        "        for cell in cell_df_con.index:\n",
        "            try:\n",
        "                multi_vals = cell_df_con.loc[cell,col]\n",
        "                multi_vals = consolidate_iv_recs(multi_vals)\n",
        "            except:\n",
        "                if np.isnan(multi_vals): multi_vals = None\n",
        "                else: multi_vals = 'ERROR'       \n",
        "\n",
        "            if not isinstance(multi_vals, list): multi_vals=[multi_vals]\n",
        "            cell_df_con.at[cell,col] = multi_vals\n",
        "\n",
        "    for cell in cell_df_con.index:\n",
        "        multi_val_pair = (cell_df_con.loc[cell,'Stim_Levels_(pA)'], cell_df_con.loc[cell,'Spike_Counts'])\n",
        "        multi_val_pair = consolidate_gain_recs(multi_val_pair)\n",
        "\n",
        "        new_stim = multi_val_pair[0]\n",
        "        new_firing = multi_val_pair[1]\n",
        "        if len(new_stim)>0:\n",
        "            if isinstance(new_stim[0],list):\n",
        "                new_stim = new_stim[0]\n",
        "        if len(new_firing)>0:\n",
        "            if isinstance(new_firing[0],list):\n",
        "                new_firing = new_firing[0]\n",
        "\n",
        "        cell_df_con.at[cell,'Stim_Levels_(pA)'] = new_stim\n",
        "        cell_df_con.at[cell,'Spike_Counts'] = new_firing\n",
        "\n",
        "    return cell_df_con\n",
        "\n",
        "def consolidate_iv_recs(multi_vals):\n",
        "    multi_vals = [v for v in multi_vals if v is not None]   \n",
        "    v_stim = [  mv['V_stim'] for mv in  multi_vals ]\n",
        "    peak_vals = [  mv['I_peak'] for mv in  multi_vals ]\n",
        "    if len(v_stim)>1:\n",
        "        rec_lengths = [len(v) for v in v_stim]\n",
        "        long_enough = np.where(np.array(rec_lengths) > 5)[0][0]\n",
        "        multi_vals = multi_vals[long_enough]\n",
        "        # print(multi_vals)  \n",
        "    return multi_vals\n",
        "\n",
        "def simplify_dicts(cell_df,cols_to_simplify,remove_source = True):\n",
        "    cell_df_new = cell_df.copy()\n",
        "    for col in cols_to_simplify:\n",
        "        for cell in cell_df_new.index:\n",
        "            list_of_dicts = cell_df_new.loc[cell,col]\n",
        "            list_of_dicts = [d for d in list_of_dicts if d is not None]\n",
        "            if len(list_of_dicts) == 0: continue\n",
        "            # print(list_of_dicts)\n",
        "            list_of_keys = list(list_of_dicts[0].keys())            \n",
        "            for k in list_of_keys:\n",
        "                vals_of_key = []\n",
        "                for i in range(len(list_of_dicts)):\n",
        "                    vals_of_key.append(  list_of_dicts[i][k] )\n",
        "                if len(vals_of_key) == 1: vals_of_key = vals_of_key[0]\n",
        "                new_col = col + '_(' + str(k) +')'\n",
        "                if new_col not in cell_df_new.columns: \n",
        "                    cell_df_new[new_col] = None\n",
        "                    cell_df_new[new_col] = cell_df_new[new_col].astype(object)\n",
        "                cell_df_new.at[cell,new_col] = vals_of_key\n",
        "        cell_df_new.drop(labels=col, axis = 1,inplace = True)\n",
        "    return cell_df_new\n",
        "\n",
        "def consolidate_gain_recs(multi_val_pair):\n",
        "    min_stims = 5\n",
        "    mv_stim = multi_val_pair[0]\n",
        "    mv_fire = multi_val_pair[1]\n",
        "    mv_stim = [v.tolist() for v in mv_stim if v is not None]\n",
        "    mv_fire = [v.tolist() for v in mv_fire if v is not None]\n",
        "    results = (mv_stim, mv_fire)\n",
        "\n",
        "\n",
        "    if len(mv_stim)>1:\n",
        "        rec_lengths = [len(v) for v in mv_stim]\n",
        "        mv_stim = [v for v in mv_stim if len(v) >=min_stims]\n",
        "        mv_fire = [v for v in mv_fire if len(v) >=min_stims]\n",
        "\n",
        "    results = (mv_stim, mv_fire)\n",
        "    \n",
        "    if len(mv_stim)>1:\n",
        "        stim_set = list(set( [vv for v in mv_stim for vv in v] ))# flat_list = [item for sublist in regular_list for item in sublist]\n",
        "        stim_set.sort()\n",
        "        new_vals_dict = {}\n",
        "        for s in stim_set:\n",
        "            matching_response =[]\n",
        "            matching_stim = []\n",
        "            for i in range(len(mv_stim)):\n",
        "                for j in range(len(mv_stim[i])):\n",
        "                    if mv_stim[i][j] == s:\n",
        "                        matching_stim.append(mv_stim[i][j])\n",
        "                        matching_response.append(mv_fire[i][j])\n",
        "            new_vals_dict[s] =  matching_response\n",
        "        new_stim_list = []\n",
        "        new_response_list = []\n",
        "        for k in new_vals_dict:\n",
        "            new_vals_dict[k] = np.mean(new_vals_dict[k])\n",
        "            new_stim_list.append(k)\n",
        "            new_response_list.append(new_vals_dict[k])\n",
        "\n",
        "\n",
        "        results = (new_stim_list, new_response_list)\n",
        "        \n",
        "    return results\n",
        "\n",
        "cell_df = cell_sorting(abf_recordings_df)\n",
        "\n",
        "list_types = ['Recording_name','protocol','abf_timestamp', 'channelList']\n",
        "any_types = ['Rec_date',\t'Virus',\t'GenoType',\t'Sex',\t'Age',\t'Slice_Num',  'Cell_num', 'Cell_Type']\n",
        "cell_df_con = cell_consolidation(cell_df,list_types,any_types)\n",
        "\n",
        "cols_to_simplify = ['IV_Early', 'IV_Steady_State']\n",
        "cell_df_nd = simplify_dicts(cell_df_con,cols_to_simplify)             \n",
        "\n"
      ],
      "metadata": {
        "id": "GtJUI1kFl0eJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IXOTBRbO8oi",
        "outputId": "329b758c-42aa-47b5-ec67-b957d8995717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_and_data_cols={'Stim_Levels_(pA)': ['Stim_Levels_(pA)', 'Spike_Counts' ],\n",
        "                    'IV_Early_(V_stim)': ['IV_Early_(V_stim)', 'IV_Early_(I_peak)', 'IV_Steady_State_(I_mean)']}\n",
        " \n",
        " \n",
        "def csv_frinedly(cell_df,keys_and_data_cols,remove_source = True):\n",
        "    cell_df_csv = cell_df.copy()\n",
        "    for k in keys_and_data_cols.keys():\n",
        "        for data_col in keys_and_data_cols[k]:\n",
        "            for cell in cell_df_csv.index:\n",
        "                label_value_list = cell_df_csv.loc[cell,k]\n",
        "                data_value_list = cell_df_csv.loc[cell,data_col]\n",
        "                if label_value_list is None: continue\n",
        "                label_value_len = len( label_value_list)\n",
        "                for i in range(label_value_len):\n",
        "                    new_col_name = data_col + '_' + str( cell_df_csv.loc[cell,k][i])\n",
        "                    if new_col_name not in cell_df_csv.columns: cell_df_csv[new_col_name] = None\n",
        "                    cell_df_csv.at[cell,new_col_name] = data_value_list[i]\n",
        "\n",
        "    return cell_df_csv\n",
        "\n",
        "cell_df_csv = csv_frinedly(cell_df_nd,keys_and_data_cols)\n",
        "# cell_df_csv.to_csv('cell_df_csv.csv')\n",
        "# files.download('cell_df_csv.csv')   "
      ],
      "metadata": {
        "id": "52YMU0DlsYWL"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def current_density_correction(cell_df,size_col,current_col_list,remove_old=True):\n",
        "    cell_df_cd = cell_df.copy()\n",
        "    ccl_exp = []\n",
        "    for ccl in current_col_list:\n",
        "        ccl_exp = ccl_exp + [c for c in cell_df.columns if ccl in c]\n",
        "    current_col_list = ccl_exp\n",
        "    for cell in cell_df.index:\n",
        "        size = cell_df.loc[cell,size_col]\n",
        "        for col in current_col_list:\n",
        "            try:\n",
        "                new_col = col +'_pApF'\n",
        "                cell_df_cd.at[ cell,new_col] = cell_df_cd.at[ cell,col] / size\n",
        "            except: \n",
        "                cell_df_cd.at[ cell,new_col] = None\n",
        "    \n",
        "    cell_df_cd = cell_df_cd[[ c for c in cell_df_cd.columns if c not in current_col_list ]]\n",
        "\n",
        "    return cell_df_cd\n",
        "\n",
        "size_col = 'Cmq_160.0'\n",
        "current_col_list = ['IV_Early_(I_peak)_', 'IV_Steady_State_(I_mean)_']\n",
        "cell_df_csv = current_density_correction(cell_df_csv, size_col, current_col_list)"
      ],
      "metadata": {
        "id": "v9ohdnX1QcpI"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl\n",
        "!pip install XlsxWriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-mIEwgA0NTT",
        "outputId": "4330599a-bb85-467e-95e8-6a8e53248938"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: XlsxWriter in /usr/local/lib/python3.7/dist-packages (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### abridge df\n",
        "\n",
        "\n",
        "abrg_exclusions = ['Recording_name', \n",
        "                   'protocol', 'abf_timestamp', 'channelList',  'Ra_10.0', 'Rm_10.0', 'tau_10.0', 'Cmq_10.0', 'Cmf_10.0',\n",
        "                   'Cmqf_10.0',  'Cmf_160.0', 'Cmqf_160.0', 'Cm_pc_160.0',\n",
        "                    'Gain_R2', 'Stim_Levels_(pA)', 'Spike_Counts', 'Firing_Duration_%', 'Gain_Vh',  'Vhold_spike',\n",
        "                    'Rin_Rsqr',  'Ramp_AP_thresh', 'Ramp_Vh', 'Ramp_Rheobase', \n",
        "                   'ap_thresh_us', 'v_half',\n",
        "                   'IV_Early_(range)', 'IV_Early_(I_peak)', 'IV_Early_(I_mean)', 'IV_Early_(V_stim)', 'IV_Steady_State_(range)',\n",
        "                   'IV_Steady_State_(I_peak)', 'IV_Steady_State_(I_mean)', 'IV_Steady_State_(V_stim)', ]\n",
        "\n",
        "abrg_keep = [c for c in cell_df_csv.columns if c not in abrg_exclusions]\n",
        "cell_df_csv_abrg = cell_df_csv[abrg_keep]\n",
        "\n"
      ],
      "metadata": {
        "id": "hJ0XlkF3yyNh"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( [c for c in cell_df_csv.columns])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iH2JPszy8H6",
        "outputId": "ae78afbb-e0f7-4bec-b25c-af1ba2dca8f0"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Recording_name', 'Rec_date', 'Virus', 'GenoType', 'Sex', 'Age', 'Slice_Num', 'Cell_num', 'Cell_Type', 'protocol', 'abf_timestamp', 'channelList', 'Rmp_mV', 'Ra_10.0', 'Rm_10.0', 'tau_10.0', 'Cmq_10.0', 'Cmf_10.0', 'Cmqf_10.0', 'Cm_pc_10.0', 'Ra_160.0', 'Rm_160.0', 'tau_160.0', 'Cmq_160.0', 'Cmf_160.0', 'Cmqf_160.0', 'Cm_pc_160.0', 'Gain_(Hz/pA)', 'Gain_R2', 'Stim_Levels_(pA)', 'Spike_Counts', 'Firing_Duration_%', 'Gain_Vh', 'Rheobase', 'Vhold_spike', 'AP_thresh', 'Input_Resistance_MO', 'Rin_Rsqr', 'Spike_latency_(ms)', 'Ramp_AP_thresh', 'Ramp_Vh', 'Ramp_Rheobase', 'v_max', 'fast_after_hyperpol', 'ap_thresh_us', 'v_half', 'ap50_width_ms', 'rise_time_ms', 'fall_time_ms', 'dv_max', 'dv_min', 'AP_thresh_US', 'IV_Early_(range)', 'IV_Early_(I_peak)', 'IV_Early_(I_mean)', 'IV_Early_(V_stim)', 'IV_Steady_State_(range)', 'IV_Steady_State_(I_peak)', 'IV_Steady_State_(I_mean)', 'IV_Steady_State_(V_stim)', 'Stim_Levels_(pA)_0.0', 'Stim_Levels_(pA)_50.0', 'Stim_Levels_(pA)_100.0', 'Stim_Levels_(pA)_150.0', 'Stim_Levels_(pA)_200.0', 'Stim_Levels_(pA)_250.0', 'Stim_Levels_(pA)_300.0', 'Stim_Levels_(pA)_350.0', 'Stim_Levels_(pA)_400.0', 'Stim_Levels_(pA)_450.0', 'Spike_Counts_0.0', 'Spike_Counts_50.0', 'Spike_Counts_100.0', 'Spike_Counts_150.0', 'Spike_Counts_200.0', 'Spike_Counts_250.0', 'Spike_Counts_300.0', 'Spike_Counts_350.0', 'Spike_Counts_400.0', 'Spike_Counts_450.0', 'IV_Early_(V_stim)_-130', 'IV_Early_(V_stim)_-120', 'IV_Early_(V_stim)_-110', 'IV_Early_(V_stim)_-100', 'IV_Early_(V_stim)_-90', 'IV_Early_(V_stim)_-80', 'IV_Early_(V_stim)_-70', 'IV_Early_(V_stim)_-60', 'IV_Early_(V_stim)_-50', 'IV_Early_(V_stim)_-40', 'IV_Early_(V_stim)_-30', 'IV_Early_(V_stim)_-20', 'IV_Early_(V_stim)_-10', 'IV_Early_(V_stim)_0', 'IV_Early_(V_stim)_10', 'IV_Early_(V_stim)_-140', 'IV_Early_(I_peak)_-130_pApF', 'IV_Early_(I_peak)_-120_pApF', 'IV_Early_(I_peak)_-110_pApF', 'IV_Early_(I_peak)_-100_pApF', 'IV_Early_(I_peak)_-90_pApF', 'IV_Early_(I_peak)_-80_pApF', 'IV_Early_(I_peak)_-70_pApF', 'IV_Early_(I_peak)_-60_pApF', 'IV_Early_(I_peak)_-50_pApF', 'IV_Early_(I_peak)_-40_pApF', 'IV_Early_(I_peak)_-30_pApF', 'IV_Early_(I_peak)_-20_pApF', 'IV_Early_(I_peak)_-10_pApF', 'IV_Early_(I_peak)_0_pApF', 'IV_Early_(I_peak)_10_pApF', 'IV_Early_(I_peak)_-140_pApF', 'IV_Steady_State_(I_mean)_-130_pApF', 'IV_Steady_State_(I_mean)_-120_pApF', 'IV_Steady_State_(I_mean)_-110_pApF', 'IV_Steady_State_(I_mean)_-100_pApF', 'IV_Steady_State_(I_mean)_-90_pApF', 'IV_Steady_State_(I_mean)_-80_pApF', 'IV_Steady_State_(I_mean)_-70_pApF', 'IV_Steady_State_(I_mean)_-60_pApF', 'IV_Steady_State_(I_mean)_-50_pApF', 'IV_Steady_State_(I_mean)_-40_pApF', 'IV_Steady_State_(I_mean)_-30_pApF', 'IV_Steady_State_(I_mean)_-20_pApF', 'IV_Steady_State_(I_mean)_-10_pApF', 'IV_Steady_State_(I_mean)_0_pApF', 'IV_Steady_State_(I_mean)_10_pApF', 'IV_Steady_State_(I_mean)_-140_pApF']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import openpyxl \n",
        "# import xlsxwriter\n",
        "\n",
        "\n",
        "def stratify_cells(cell_df,strat_col,xl_file_name='stratified_data.xlsx'):\n",
        "    types = list(set(cell_df[strat_col]))\n",
        "\n",
        "    new_dfs = {}\n",
        "    options = {}\n",
        "    options['strings_to_formulas'] = False\n",
        "    options['strings_to_urls'] = False\n",
        "    writer = pd.ExcelWriter(xl_file_name, options=options)\n",
        "    for t in types:\n",
        "        is_type = cell_df[strat_col] == t\n",
        "        new_dfs[t] = cell_df[is_type]\n",
        "        new_dfs[t].to_excel(writer, sheet_name=str(t))\n",
        "        # new_dfs[t].to_csv(str(t) + '_cell_df_csv.csv')\n",
        "        # files.download(str(t) + '_cell_df_csv.csv')\n",
        "    writer.save()\n",
        "    writer.close()\n",
        "    files.download(xl_file_name)\n",
        "    return new_dfs\n",
        "\n",
        "\n",
        "\n",
        "strat_col = 'Cell_Type'\n",
        "xl_file_name='RNF182.xlsx'\n",
        "new_dfs = stratify_cells(cell_df_csv_abrg,strat_col,xl_file_name)\n",
        "# display(new_dfs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nW7uy85HO0U8",
        "outputId": "d3ac2822-f460-4005-a763-1d966f2f524e"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e76b1c46-9ee4-40f3-8df4-61c3e9584f79\", \"RNF182.xlsx\", 29603)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclusions = ['Recording_name', 'Rec_date', 'Virus', 'GenoType', 'Sex',\n",
        "              'Age', 'Slice_Num', 'Cell_num', 'Cell_Type', 'protocol',\n",
        "              'abf_timestamp', 'channelList', 'Stim_Levels_(pA)', 'Spike_Counts',\n",
        "              'IV_Steady_State_(V_stim)', 'IV_Steady_State_(I_peak)', 'IV_Steady_State_(I_mean)',\n",
        "              'IV_Early_(range)','IV_Early_(I_peak)','IV_Early_(I_mean)','IV_Early_(V_stim)','IV_Steady_State_(range)' ]\n",
        "\n",
        "control_df = new_dfs['CA3xNEG']\n",
        "test_df = new_dfs['CA3xPOS']\n",
        "focus_col = 'Rec_date'\n",
        "\n",
        "\n",
        "control_df_norm, test_df, control_means = daily_norm(control_df,test_df,focus_col,exclusions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjJvLfUET9tv",
        "outputId": "ff3933ed-8824-4d2d-b639-6725a23e9639"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022x08x12_RNF182_E4KI_F_P251_s001_c003_CA3xNEG\n",
            "IV_Early_(V_stim)_-140\n",
            "-140.0\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}